% Chapter 1

\chapter{Introduction} % Main chapter title

\label{Chapter1} % For referencing the chapter elsewhere, use \ref{Chapter1}

%----------------------------------------------------------------------------------------
%	PROJECT BACKGROUND
%----------------------------------------------------------------------------------------

\lhead{Chapter 1. \emph{Introduction}} % This is for the header on each page - perhaps a shortened title

Modern organisations solve difficult problems that require complex decision making and reasoning involving partial and often conflicting information. Examples of such problems are found in many different contexts: in management at large companies, in medicine, in the command of military units or in investment banking. In companies, management must make decisions about next years products without knowing what products their competitors will release and without a full insight into why their current products are performing the way they are. Doctors may have to treat unconscious patients in emergency situations. Without access to a patient’s medical records or being able to talk to them a doctor cannot access critical information about patient; for example, what medication the patient may currently be taking which could interfere with certain treatments. Without this crucial information a doctor must make assumptions, apply a reasoning process and prescribe a treatment based solely on what she can observe, with incomplete information. In the context of modern warfare, military strikes may put the lives of civilians at risk. The decision to attack is a difficult one made by military commanders. It is made more difficult in the case of guerrilla warfare, in which information is often conflicting as enemy combatants are embedded amongst ordinary citizens. 

The rapid evolution of technology is increasing the amount of data that can be gathered about these problems. Product sentiment information can be gathered from social media; improved patient monitoring gives doctors better insight into a patient’s condition; government agencies gather information from emails and phone calls. The abundance of information associated with these problems make unaided decision making difficult and reasoning a non-trivial task. Decisions Support Systems (DSS) attempt to aid decision makers in solving these problems by presenting information in a manner that makes it easier to reason about. \cite{turban2005decision} explain that the central purpose of Decision Support Systems is to support and improve decision making. Many Decision Support Systems make use of intelligent components to provide an improved understanding of the problem at hand to decision makers. \textit{The purpose of this research study is to investigate two of the approaches used in the design of these intelligent components; learning based approaches and knowledge based ones}.

Learning based approaches modify their underlying models for data based on experience. Supervised machine learning makes predictions based on a labeled training set of data. Machine learning techniques can provide reasonable predictions based on data, however, they often fall short in presenting their process to the user. As machine learning is automatic it is unsuitable for the representation of complex constructs such as an expert's knowledge.

Knowledge based approaches focus on the acquisition and representation of knowledge as well as the modeling of processes of reasoning about that knowledge. Defeasible reasoning is one such approach. An expert in a field typically doesn't look at some variables and apply a function to them. She considers the information at hand and reasons about it in the context of what she already knows. Within her reasoning process she may make assumptions that get changed as a result of the reasoning process. This reasoning process is better reflected in Defeasible Reasoning which offers a solution to the short comings of the automatic process of ML.

%----------------------------------------------------------------------------------------
%	BACKGROUND
%----------------------------------------------------------------------------------------

\section{Background}

The process by which humans reason has typically been examined in the fields of Philosophy and Psychology but has been further investigated by the field of computer science in the last 30 years or so. This investigation began in order to develop ``expert systems'': systems that attempt to model and elicit the reasoning of an expert in a computer. In an expert system a knowledge engineer typically uses a number of knowledge elicitation techniques to compile expertise in a particular domain. The knowledge engineer inputs this knowledge into the system in the form of rule sets. These rule sets can be used by an inference engine to produce useful output based on input data. 

Expert Systems have evolved in the last few decades with computer scientists looking to Psychology and Philosophy to develop a greater understanding of how reasoning works. Several mechanisms by which humans reason have identified.

On one hand is deductive reasoning; reasoning in which conclusions logically follow from a set of premises falls into a category known as monotonic reasoning(\cite{baroni1997full}). In monotonic reasoning proof of the conclusions is embedded in the premises.

On the other hand is defeasible reasoning (DR), defined by \cite{pollock1987defeasible} as reasoning in which ``the premises taken by themselves may justify accepting the conclusion, but when additional information is added, that conclusion is no longer justified.'' Non-monotonic reasoning is more suitable for modelling human reasoning, which is non-monotonic, and for implementation in DSS.

As a result of recent advances, it is possible to model defeasible reasoning using argumentation theory, a computational technique to model non-monotonic reasoning. Argumentation theory allows us to model arguments and the interactions between them. An overview of this technique is given in Chapter 2.

Knowledge based argumentation systems have many other characteristics that make their use in decision support systems advantageous. Argumentation systems can implement reasoning based on incomplete or corrupt data as well as conflicting information and explain how an algorithm arrived at a conclusion. Through the process of visualising a knowledge base using an argumentation tool an expert may gain insight into his own ideas and refine them. 

Knowledge based approaches accrue their insights and advantages by having a human expert interacting with the system. These benefits are lacking in machine learning based systems. 

On one hand, ML provides us with an approach that is automatable and can provide insights into data that it is unlikely any human would find sifting through large amounts of data by hand. ML is a better approach to solving classification problems such as natural language processing as well as image and handwriting recognition; tasks where it is difficult for a human to encode their understanding in a way that a machine can process.

On the other hand, ML is not always suited to modelling constructs, as human expertise is not accounted for. Knowledge based approaches are better suited to defining new measures for intelligence, depression, personality, or mental workload. These constructs are ill defined concepts that are difficult to measure and assess.

%-----------------------------------
%	RESEARCH Project
%-----------------------------------

\section{Research Project}

%highlight the problem and the research question.

This research project aims to provide a comparison between an implementation of DR (argumentation theory) and a type of machine learning (supervised ML). The aim is to outline the strengths of both techniques and provide guidelines on what problems a particular approach may be suited for. 

The comparison will build on previous research by evaluating the ability of the approaches to model a construct, to measure and assess it and determine the capacity of these assessments to be used in prediction tasks. 

The research question is formally defined:

``To what extent can an implementation of Defeasible Reasoning enhance the representation of a construct (mental workload) and support prediction capacity in comparison with Machine Learning?''


%-----------------------------------
%	RESEARCH OBJECTIVES
%-----------------------------------

\section{Research Objectives}

The objective of this project is to provide an overview of the differences and similarities in learning based and knowledge based approaches and to investigate the strengths and weaknesses of these approaches, in relation to construct modelling, assessment and prediction capacity.

The goals of the research project are outlined as follows:

\begin{enumerate}
  \item To gain knowledge of Defeasible Reasoning and it's implementation techniques and also to to gain knowledge of and define relevant concepts in machine learning.
  \item To design a computable model of DR for construct representation as well as a structured experiment.
  \item To implement this model in software and execute the experiments.
  \item To evaluate the designed model.
\end{enumerate}

%-----------------------------------
%	RESEARCH METHODOLOGY
%-----------------------------------

\section{Research Methodology}


This project will use a mixed research methodology - a combination of both qualitative and quantitative methods. 

\begin{enumerate}
  \item A literature review is carried out to outline the strengths and weaknesses of the techniques.
  \item The output of the review is used to inform the design of an experiment.
  \item This will utilise a software implementation of argumentation theory and machine learning tools. 
  \item  The output of this experiment is qualitatively analysed using evaluation metrics as emerged from the literature review. Statistical methods are used on the results produced in the experiment to analyse the predictive capacity of the designed model of DR against the one of selected supervised machine learning classifiers.
\end{enumerate}

%----------------------------------------------------------------------------------------
%	SCOPE AND LIMITATIONS
%----------------------------------------------------------------------------------------

\section{Scope and Limitations}

The project scope is that of a single construct. Mental Workload has been modeled as a defeasible construct in previous work by Dr. Longo who has provided his knowledge base for the purpose of the experiment. 

The project is limited by the size of the data set that has been used and provided by Dr. Longo. As there are only 440 rows in the data set the training of the machine learning models will not be thorough. 

\section{Document Outline}

This thesis is organised into the following sections:

\begin{itemize}

  \item Chapter 2 provides a review of the literature relevant to argumentation theory and machine learning including cutting-edge research in the area.
  \item Chapter 3 outlines the design of the DR implementation and the experiment and the justification of those design decisions in the context of the research methodology
  \item Chapter 4 details the implementation of the software and the experiments; the implementation and deployment of relevant software artifacts, their use and the overall execution of the experiments.
  \item Chapter 5 presents and discusses the results of the experiments.
  \item Chapter 6 summarises the thesis, highlighting it's main contribution to the body of knowledge. Future work and recommendations are suggested.

\end{itemize}
