% Chapter 1

\chapter{Introduction} % Main chapter title

\label{Chapter1} % For referencing the chapter elsewhere, use \ref{Chapter1}

%----------------------------------------------------------------------------------------
%	PROJECT BACKGROUND
%----------------------------------------------------------------------------------------

\lhead{Chapter 1. \emph{Introduction}} % This is for the header on each page - perhaps a shortened title

Modern organisations solve difficult problems that require complex decision making and reasoning involving partial and often conflicting information. Examples of such problems are found in many different contexts: in management at large companies, in medicine, in the command of military units or in investment banking. In companies, management must make decisions about next years products without knowing what products their competitors will release and without a full insight into why their current products are performing the way they are. Doctors may have to treat unconscious patients in emergency situations. Without access to a patient’s medical records or being able to talk to them a doctor cannot access critical information about patient; for example, what medication the patient may currently be taking which could interfere with certain treatments. Without this crucial information a doctor must make assumptions, apply a reasoning process and prescribe a treatment based solely on what she can observe, with incomplete information. In the context of modern warfare, military strikes may put the lives of civilians at risk. The decision to attack is a difficult one made by military commanders. It is made more difficult in the case of guerrilla warfare, in which information is often conflicting as enemy combatants are embedded amongst ordinary citizens. 

The rapid evolution of technology is increasing the amount of data that can be gathered about these problems. Product sentiment information can be gathered from social media; improved patient monitoring gives doctors better insight into a patient’s condition; government agencies gather information from emails and phone calls. The abundance of information associated with these problems make unaided decision making difficult and reasoning a non-trivial task. Decisions Support Systems (DSS) attempt to aid decision makers in solving these problems by presenting information in a manner that makes it easier to reason about. \cite{turban2005decision} explain that the central purpose of Decision Support Systems is to support and improve decision making. Many Decision Support Systems make use of intelligent components to provide an improved understanding of the problem at hand to decision makers. \textit{The purpose of this research study is to investigate two of the approaches used in the design of these intelligent components; learning based approaches and knowledge based ones}.

Learning based approaches modify their underlying models for data based on experience. Supervised machine learning makes predictions based on a labeled training set of data. Machine learning techniques can provide reasonable predictions based on data, however, they often fall short in presenting their process to the user. As machine learning is automatic it is unsuitable for the representation of complex constructs such as an expert's knowledge.

Knowledge based approaches focus on the acquisition and representation of knowledge as well as the modeling of processes of reasoning about that knowledge. Defeasible reasoning is one such approach. An expert in a field typically doesn't look at some variables and apply a function to them. She considers the information at hand and reasons about it in the context of what she already knows. Within her reasoning process she may make assumptions that get changed as a result of the reasoning process. This reasoning process is better reflected in Defeasible Reasoning which offers a solution to the short comings of the automatic process of ML.

%----------------------------------------------------------------------------------------
%	BACKGROUND
%----------------------------------------------------------------------------------------

\section{Background}

The process by which humans reason has typically been examined in the fields of Philosophy and Psychology but has been further investigated by the field of computer science in the last 30 years or so. This investigation began in order to develop ``expert systems'': systems that attempt to model and elicit the reasoning of an expert in a computer. In an expert system a knowledge engineer typically uses a number of knowledge elicitation techniques to compile expertise in a particular domain. The knowledge engineer inputs this knowledge into the system in the form of rule sets. These rule sets can be used by an inference engine to produce useful output based on input data. 

Expert Systems have evolved in the last few decades with computer scientists looking to Psychology and Philosophy to develop a greater understanding of how reasoning works. Several mechanisms by which humans reason have identified.

On one hand is deductive reasoning; reasoning in which conclusions logically follow from a set of premises falls into a category known as monotonic reasoning(\cite{baroni1997full}). In monotonic reasoning proof of the conclusions is embedded in the premises.

On the other hand is defeasible reasoning (DR), defined by \cite{pollock1987defeasible} as reasoning in which ``the premises taken by themselves may justify accepting the conclusion, but when additional information is added, that conclusion is no longer justified.'' Non-monotonic reasoning is more suitable for modelling human reasoning, which is non-monotonic, and for implementation in DSS.

As a result of recent advances, it is possible to model defeasible reasoning using argumentation theory, a computational technique to model non-monotonic reasoning. Deasible relationships between those arguements are modeled as edges. An overview of this technique is given in Chapter 2.

Argumentation systems have many other characteristics that make their use in decision support systems advantageous. Argumentation systems can reason based on incomplete or corrupt data and explain how an algorithm arrived at a conclusion. Through the process of visualising a knowledge base using an argumentation tool an expert may gain insight into his own ideas and refine them. 

Knowledge based approaches accrue their insights and advantages by having a human expert interacting with the system. These benefits are lacking in machine learning based systems. However, ML provides us with an approach that is automatable and can provide us insights into data that it is unlikely any human would like to by going through large amounts of data by hand. ML is a better approach to solving problems such as natural language processing and image and handwriting recognition; tasks where it is difficult for a human to encode their understanding in a way that a machine can process.

Research in the area suggests that that defeasible reasoning approaches can perform as well as state-of-the-art machine learning approaches in the prediction of breast cancer recurrence with several additional benefits. However, there is no comparison of the ability of the techniques to model a construct; a value that is not present in the data to begin with.

%-----------------------------------
%	RESEARCH Project
%-----------------------------------

\section{Research Project}

%highlight the problem and the research question.

This research project aims to provide a comparison between Argumentation Theory and Supervised Machine Learning. The case is made for knowledge-base paradigms as practical alternatives to learning based ones. This research aims to outlines the strengths of both techniques and provide guidelines on what problems a particular approach may be suited for. 

The comparison will build on previous research by evaluating the ability of the approaches to model a construct, rather than labels already present in the data. The research question is formally defined:

``To what extent can an implementation of Defeasible Reasoning enhance the representation of a construct and support prediction capacity in comparison with Machine Learning?''


%-----------------------------------
%	RESEARCH OBJECTIVES
%-----------------------------------

\section{Research Objectives}

The objective of this project is to provide an overview of the differences and similarities in learning based and knowledge based approaches and to investigate the strengths and weaknesses of these approaches. 

The goals of the research project are outlined as follows:

\begin{itemize}

  \item To gain knowledge of Defeasible Reasoning and DR implementation techniques.
  \item To gain knowledge of and define relevant concepts in machine learning.
  \item To design a computable model of DR for knowledge representation.
  \item To implement this model.
  \item To design an experiment to compare machine learning and argumentation theory.
  
\end{itemize}

%-----------------------------------
%	RESEARCH METHODOLOGY
%-----------------------------------

\section{Research Methodology}


This project will use a mixed research methodology - a combination of both qualitative and quantitative methods. A literature review is carried out to outline the strengths and weaknesses of the techniques that have been identified in previous research. The output of the review is used to inform the design of an experiment that will utilise a software implementation of argumentation theory and machine learning tools. The output of this experiment is qualitatively analysed in the context of the information obtained in the literature review. Statistical methods are used on the data produced from the experiment analyse the predictive capacity of argumentation theory and supervised machine learning. 

As part of the project the development of an argumentation system inspired by the research of Dung and Longo and Hederman is developed to allow for a comparison with machine learning software, Weka. 

In order to achieve the aforementioned aims the following experiments are conducted.

\begin{itemize}

  \item An argumentation system is developed in software and used to elicit a knowledge base from an expert.
  \item A number of ML classifiers (using both classification and regression algorithms) are trained to using a partition of the experiment data set.
  \item The predictive ability of the classifiers and the knowledge based system are tested using a subset of the data set.

\end{itemize}


%----------------------------------------------------------------------------------------
%	SCOPE AND LIMITATIONS
%----------------------------------------------------------------------------------------

\section{Scope and Limitations}

The project scope is that of Mental Workload. Mental Workload has been modeled as a defeasible construct in previous work by Dr. Longo who will provide his knowledge base for the purpose of the experiment. 

The project is limited by the size of the data set that will be used. As there are only 440 rows in the data set the training of the machine learning models will not be thorough. 

\section{Document Outline}

This thesis is organised into the following sections:

\begin{itemize}

  \item Chapter 2 provides a review of the literature relevant to argumentation theory and machine learning including cutting-edge research in the area.
  \item Chapter 3 outlines the design of the experiment and the justification of those design decisions in the context of previous research methodology
  \item Chapter 4 details the implementation of the experiments; the implementation relevant software artifacts, their use and the overall execution of the experiments.
  \item Chapter 5 the results of the experiments are presented and discussed.
  \item Chapter 6 reviews the experiment and findings in the context of the relevant literature. Conclusions are then derived and future work suggested.

\end{itemize}
