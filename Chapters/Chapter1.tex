% Chapter 1

\chapter{Introduction} % Main chapter title

\label{Chapter1} % For referencing the chapter elsewhere, use \ref{Chapter1}

%----------------------------------------------------------------------------------------
%	PROJECT BACKGROUND
%----------------------------------------------------------------------------------------

\lhead{Chapter 1. \emph{Introduction}} % This is for the header on each page - perhaps a shortened title

This chapter introduces the research topic, defeasible reasoning and outlines it's potential as an alternative to machine learning in predicting constructs. The aims and reasoning of this research study are clarified. The research methodology is discussed along with the scope and limitations of the study. Finally the organisation of this document is presented to the reader.

%----------------------------------------------------------------------------------------
%	PROJECT BACKGROUND
%----------------------------------------------------------------------------------------

\section{Overview of Project Area}

Modern organisations solve difficult problems that require complex decision making and involve partial and often conflicting information. Examples of such problems are found in many different contexts; in management at large companies, in medicine, in the command of military units or in investment banking.

In companies, management must make decisions about next years products without knowing what products their competitors will release and without a full insight into why their current products are performing the way they are.

Doctors may have to treat unconscious patients in emergency situations. Without access to a patient’s medical records or being able to talk to them a doctor cannot access critical information about patient; for example, what medication the patient may currently be taking which could interfere with certain treatments. Without this crucial information a doctor must make assumptions, apply a reasoning process and prescribe a treatment based solely on what she can observe, with incomplete information.

In the context of modern warfare, military strikes may put the lives of civilians at risk. The decision to attack is a difficult one made by military commanders. It is made more difficult in the case of guerrilla warfare, in which information is often conflicting as enemy combatants are embedded amongst ordinary citizens.

The rapid evolution of technology is increasing the amount of data that can be gathered about these problems. Product sentiment information can be gathered from social media; improved patient monitoring gives doctors better insight into a patient’s condition; government agencies gather information from emails and phone calls. The abundance of information associated with these problems make unaided decision making impossible. 

Decisions Support Systems attempt to aid decision makers in solving these problems by presenting information in a manner that makes it easier to reason about. \cite{turban2005decision} explain that the central purpose of Decision Support Systems is to support and improve decision making. Many Decision Support Systems make use of intelligent components to provide an improved understanding of the problem at hand to decision makers. The purpose of this research study is to investigate two of the approaches used in the design of these intelligent components; learning based approaches and knowledge based ones.

Learning based approaches modify their underlying models for data based on experience. Supervised machine learning makes predictions based on a labeled training set of data. Machine learning techniques can provide reasonable predictions based on data, however, they often fall short in presenting their process to the user. As machine learning is automatic it is unsuitable for the representation of complex constructs such as an expert's knowledge.

Knowledge based approaches focus on the acquisition and representation of knowledge as well as the modeling of processes of reasoning about that knowledge. Defeasible reasoning is one such approach. An expert in a field typically doesn't look at some variables and apply a function to them. She considers the information at hand and reasons about it in the context of what she already knows. Within her reasoning process she may make assumptions that get changed as a result of the reasoning process. This reasoning process is better reflected in Defeasible Reasoning which offers a solution to the short comings of the automatic process of ML.

%----------------------------------------------------------------------------------------
%	BACKGROUND
%----------------------------------------------------------------------------------------

\section{Background}

The process by which humans reason has typically been examined in the fields of Philosophy and Psychology but has been further investigated by the field of computer science in the last 30 years or so. This investigation began in order to develop ``expert systems''; systems that attempt to model the reasoning of an expert in a computer.

In an expert system a knowledge engineer typically uses a number of knowledge elicitation techniques to compile expertise in a particular domain. The knowledge engineer inputs this knowledge into the system in the form of rule sets. These rule sets can be used by an inference engine to produce useful output based on input data. 

In order to build inference engines, computer scientists have looked to Psychology and Philosophy to develop a greater understanding of how reasoning works. Several mechanisms by which humans reason have identified.

Deductive reasoning is reasoning in which conclusions logically follow from a set of premises falls into a category known as monotonic reasoning. In monotonic reasoning proof of the conclusions is embedded in the premises.

Defeasible Reasoning was defined by Pollock as reasoning in which ``the premises taken by themselves may justify accepting the conclusion, but when additional information is added, that conclusion is no longer justified.''\cite{pollock1987defeasible}

It is possible to model defeasible reasoning using argumentation theory, in particular using abstract argumentation frameworks as described by Dung.\cite{dung1995acceptability} An Argumentation Framework is a directed graph in which arguments are modeled as nodes. Deasible relationships between those arguements are modeled as edges. An overview of this technique is given in Chapter 2.

Argumentation systems have many other characteristics that make their use in decision support systems advantageous. Argumentation systems can reason based on incomplete or corrupt data and explain how an algorithm arrived at a conclusion. Through the process of visualising a knowledge base using an argumentation tool an expert may gain insight into his own ideas and refine them. 

Knowledge based approaches accrue their insights and advantages by having a human expert interacting with the system. These benefits are lacking in machine learning based systems. However, ML provides us with an approach that is automatable and can provide us insights into data that it is unlikely any human would like to by going through large amounts of data by hand. ML is a better approach to solving problems such as natural language processing and image and handwriting recognition; tasks where it is difficult for a human to encode their understanding in a way that a machine can process.

Research in the area suggests that that defeasible reasoning approaches can perform as well as state-of-the-art machine learning approaches in the prediction of breast cancer recurrence with several additional benefits. However, there is no comparison of the ability of the techniques to model a construct; a value that is not present in the data to begin with.

%-----------------------------------
%	RESEARCH Project
%-----------------------------------

\section{Research Project}

%highlight the problem and the research question.

This research project aims to provide a comparison between Argumentation Theory and Supervised Machine Learning. The case is made for knowledge-base paradigms as practical alternatives to learning based ones. This research aims to outlines the strengths of both techniques and provide guidelines on what problems a particular approach may be suited for. 

The comparison will build on previous research by evaluating the ability of the approaches to model a construct, rather than labels already present in the data. The research question is formally defined:

``To what extent can an implementation of Defeasible Reasoning enhance the representation of a construct and support prediction capacity in comparison with Machine Learning?''


%-----------------------------------
%	RESEARCH OBJECTIVES
%-----------------------------------

\section{Research Objectives}

 analysis of both regression and classification approaches.

To provide an overview of the differences and similarities in learning based and knowledge based approaches. To investigate the strengths and weaknesses of these approaches. 

The goals of the research project are outlined as follows:

\begin{itemize}

  \item To gain knowledge of Defeasible Reasoning and DR implementation techniques.
  \item To gain knowledge of and define relevant concepts in machine learning.
  \item To design a computable model of DR for knowledge representation.
  \item To implement this model
  \item To design an experiment to compare machine learning and argumentation theory.
  
\end{itemize}

%-----------------------------------
%	RESEARCH METHODOLOGY
%-----------------------------------

\section{Research Methodology}


This project will use a mixed research methodology - a combination of both qualitative and quantitative methods. A literature review is carried out to outline the strengths and weaknesses of the techniques that have been identified in previous research. The output of the review is used to inform the design of an experiment that will utilise a software implementation of argumentation theory and machine learning tools. The output of this experiment is qualitatively analysed in the context of the information obtained in the literature review. Statistical methods are used on the data produced from the experiment analyse the predictive capacity of argumentation theory and supervised machine learning. 

As part of the project the development of an argumentation systems inspired by the research of Dung and Longo and Hederman is developed to allow for a comparison with machine learning software. Weka. 


In order to achieve the aforementioned aims the following experiments are conducted.

\begin{itemize}

  \item An argumentation system is developed in software and used to elicit a knowledge base from an expert.
  \item A number of ML classifiers (using both classification and regression algorithms) are trained to using a partition of the experiment dataset.
  \item The predictive ability of the classifiers and the knowledge based system are tested using a subset of tuples of the dataset.

\end{itemize}


%----------------------------------------------------------------------------------------
%	SCOPE AND LIMITATIONS
%----------------------------------------------------------------------------------------

\section{Scope and Limitations}


In this study we are restricted by several factors in the analysis of the techniques. There are several limiting factors in the experiments that are a barrier to the accurate assessment of argumentation theory. The argumentation system is limited in its predictive capacity by it’s knowledge based approach.

The project scope is that of Mental Workload. Mental Workload has been modeled as a defeasible construct in previous work by Dr. Luca Longo. 


In this study we are restricted by several factors in the analysis of the techniques.
There are several limiting factors in the experiments that are a barrier to the accurate assessment of argumentation theory.
The argumentation system is limited in it's predictive capacity by it's knowledge based approach.
The system elicits a knowledge base from an expert and assumes that the expert's knowledge accurately reflects reality.
There is no objective verification of that knowledge base. The performance of the AT system is based heavily on the knowledge of the expert and they ability of the system to model that knowledge accurately.
We are similarly limited in our evaluation of the classifiers produced using the ML approach.
Obtaining a data set of sufficient size to train classifiers to a level on par with the knowledge of an experienced professional is a challenge.

%-----------------------------------
%	DOCUMENT OUTLINE
%-----------------------------------

\section{Document Outline}

This thesis is organised into the following sections:

\begin{itemize}

  \item Chapter 2 provides a review of the literature relevant to argumentation theory and machine learning including cutting-edge research in the area.
  \item Chapter 3 outlines the design of the experiment and the justification of those design decisions in the context of previous research methodology
  \item Chapter 4 details the implementation of the experiments; the implementation relevant software artifacts, their use and the overall execution of the experiments.
  \item Chapter 5 the results of the experiments are presented and discussed.
  \item Chapter 6 reviews the experiment and findings in the context of the relevant literature. Conclusions are then derived and future work suggested.

\end{itemize}
