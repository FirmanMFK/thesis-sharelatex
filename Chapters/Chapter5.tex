% Chapter Template

\chapter{Evaluation of Results and Discussion} % Main chapter title

\label{Chapter5} % Change X to a consecutive number; for referencing this chapter elsewhere, use \ref{ChapterX}

\lhead{Chapter 5. \emph{Evaluation of Results and Discussion}} % Change X to a consecutive number; this is for the header on each page - perhaps a shortened title

This chapter discusses the ability of an implementation of defeasible reasoning to model a construct in comparison with machine learning. The chapter presents and discusses the results of the experiment performed in the previous chapter. A comparative analysis of both techniques is performed using the evaluation techniques gathered in the literature review.

\section{Results}

The research question posed at the start of this project is focused on the ability of two techniques to represent a construct and make predictions based on this representation. The predictive capacity of the techniques is presented here. In order to determine how these new measures perform, the concurrent and convergent validity of the new values is calculated using existing measures of the construct. 

\subsection{Predictive Capacity - Numeric}

In order to compare the predictive capacity of the approaches each technique was used to compute the value of an objective performance measure: time. The mean absolute error for time prediction was taken for each technique. In order to gather a wider comparison the size of the data used for training and testing was adjusted by varying the number of folds and percentage of split. Figure ~\ref{fig:mae_time} displays the results of the experiment. Immediately obvious in this graph is the poor performance of Artificial Neural Networks. According to \cite{silvert2000can} ANNs typically require large ammount of data for training. The performance of the ANN could be improved by pre-processing the data. 

The performance of the machine learning algorithms vary dramatically. It is interesting to note that simple linear regression using one variable doesn't out perform the regression based on the non-expert knowledge base. Decision table, kstar and additive regression have error rates higher than the expert knowledge base. Decision table and kstar don't correlate well with time although additive regression performs nearly as well as the expert knowledge base. A linear regression outperforms all of the techniques and can predict task time with the strongest correlation. With the exception of linear regression, the machine learning techniques all show a large variability based on the amount of data that is available for training. KStar and additive regression are outperformed by linear regression. 

\begin{figure}[!h]
\centering
\includegraphics[width=\linewidth]{mae_time}
\caption{Mean Absolute Error for Time Prediction}
\label{fig:mae_time}
\end{figure}

Table ~\ref{tab:time_predictions_fold} and table ~\ref{tab:time_predictions_split} gives a breakdown of the results that provides more clarity than the previous figures. For different numbers of folds we can see that the regressions based on the expert's knowledge base perform best of all which validates the first hypothesis of the experiment. What is interesting is that the predictions based on the knowledge of the non-expert perform better than that of the expert for varying percentage of split. As the knowledge base of the non-expert contains fewer nodes it is possible that it weighs some variable heavily that contributes greatly to task time.

\begin{table}[!htbp]
\centering
\begin{tabular}{|c|c|c|c|}
\hline
                                &  10-fold & 20-fold & 40-fold \\ \hline
ANN                             & 137.238 & 126.9808 & 141.3834 \\
K Star                          & 93.6672 & 92.1658 & 91.1066 \\
Additive Regression             & 85.8072  & 83.5995  & 82.0641 \\
Regression                      & 80.8231 & 80.9963 & 80.2697 \\
Expert (Grounded Extension)     & 80.6007 & 80.5986 & 80.5241 \\
Expert (Prefered Extension)     & 80.4185 & 80.4475 &  80.3192 \\
Non-Expert (Grounded Extension) & 81.5565 & 81.6743 & 81.7295 \\
Non-Expert (Prefered Extension) & 81.5565 & 81.6743 & 81.7295 \\
\hline
\end{tabular}
\caption{Mean Absolute Error Using K-Fold Cross Validation}
\label{tab:time_predictions_fold}
\end{table}

\begin{table}[!htbp]
\centering
\begin{tabular}{|c|c|c|c|}
\hline
                                & 30\% Split  & 50\% Split  & 70\% Split \\ \hline
ANN                             & 163.7684 & 152.5288 & 147.3721 \\
K Star                          & 101.9482 & 93.8966 & 92.0756 \\
Additive Regression             & 93.3442  & 81.2395  & 87.8533 \\
Regression                      & 83.1717 & 80.868 & 83.589 \\
Expert (Grounded Extension)     & 81.0625 & 78.0558 & 78.7381 \\
Expert (Prefered Extension)     & 80.4185 & 80.4475 &  80.3192 \\
Non-Expert (Grounded Extension) & 79.5426 & 77.2909 & 79.9484 \\
Non-Expert (Prefered Extension) & 79.5426 & 77.2909 & 79.9484 \\
\hline
\end{tabular}
\caption{Mean Absolute Error Varying Percentage of Split}
\label{tab:time_predictions_split}
\end{table}

\subsection{Predictive Capacity - Task Membership}

A comparison of the techniques ability to predict task membership was also performed. The performance of each measure was evaluated simply using 10-fold cross validation. This was chosen as there are a larger number of evaluation metrics for classifiers that are being considered here than for the numeric prediction task. The first metric that is examined is the number of correctly and incorrectly classified instances which is shown in figure ~\ref{fig:classified}. This metric shows that ANN, Naive Bayes and Logistic Regression perform best in terms of correctly classified instances. This nullifies the hypothesis that the knowledge base of the expert predicts task membership better than machine learning. In this case the knowledge base of the expert actually performed worse than the knowledge base of the non-expert.

\begin{figure}[!h]
\centering
\includegraphics[width=\linewidth]{classified_instances}
\caption{Classified Instances - Task ID}
\label{fig:classified}
\end{figure}

By examining the precision and recall of the classifiers we can gain further insight into their performance. The best performing machine learning tasks have about the same precision and recall. We can see a large variation in the precision and recall of the expert and non-expert. The recall of the non-expert is higher than that of the expert resulting in a greater number of correctly classified instances.

\begin{figure}[!h]
\centering
\includegraphics[width=\linewidth]{precision_recall_f-score}
\caption{Precision, Recall and F-Score}
\label{fig:precision_recall_f-score}
\end{figure}

The area under the ROC curve provides further clarification of the performance of the classifiers as it takes into account the number of false positives. We can see that while the non-expert may have classified more instances correctly, the expert's knowledge base provides a greater balance between true positives and false positives.  

\begin{figure}[!h]
\centering
\includegraphics[width=\linewidth]{roc_area}
\caption{Area Under ROC Curve}
\label{fig:precision_and_recall}
\end{figure}

It is interesting that the machine learning approach was more effective in determining task membership than the defeasible reasoning approach. This could be because the tasks don't vary MWL strongly enough. Whether this is true or not could be determined by taking some measure of the convergent validity of MWL and task number. Unfortunately this is not possible via a simple correlation. Another possibility is that the knowledge bases are failing to take into account some aspect of mental workload that could determine task membership better.

\subsection{Concurrent Validity}

The concurrent validity of the defeasible constructs was measured by performing regressions against time (tables ~\ref{tab:eccurrent_time} and ~\ref{tab:neccurrent_time}). Time is an objective performance measure that is similar to MWL. For all knowledge bases the error rate is high. The error rate for the expert knowledge base is slightly lower than the non-expert knowledge base. As the values of time can be anywhere from 0 to a few hundred seconds predicting time exactly from the values of MWL is extremely error prone. Moreover, the precision required for the construct of MWL doesn't need to be as precise as seconds. Correlation provides a better understanding of the performance of the knowledge base in this case. The results show a much stronger correlation between the knowledge base of the expert and time than the knowledge base of the non-expert. This provides some confirmation that the implementation is modeling defeasible knowledge bases correctly as it is expected that the knowledge base of the expert should more accurately represent MWL that that of the non-expert. The preferred extension of the knowledge base of the expert performed better than the grounded extension. The preferred extension and the grounded extension of the non-expert were determined to be equivalent by the software and so show the same results.

\begin{table}[!htbp]
\centering
\begin{tabular}{|c|c|c|}
\hline
                            &  expertGrounded & expertPref \\ \hline
Correlation coefficient     & 0.3362        & 0.3414      \\
Mean absolute error         & 80.6007       & 80.4185     \\
Root mean squared error     & 110.3579      & 110.1416  \\
Relative absolute error     & 95.9998\%     & 95.7829\% \\
Root relative squared error & 94.0706\%     & 93.8863\% \\
\hline
\end{tabular}
\caption{Expert knowledge base concurrent validity against time}
\label{tab:eccurrent_time}
\end{table}

\begin{table}[!htbp]
\centering
\begin{tabular}{|c|c|c|}
\hline
                            &   non-expertGrounded  & non-expertPref \\ \hline
Correlation coefficient     &  0.2046         & 0.2046  \\
Mean absolute error         &  81.5565        & 81.5565  \\
Root mean squared error     & 114.6813       & 114.6813  \\
Relative absolute error     & 97.1383\%      & 97.1383\%  \\
Root relative squared error & 97.756\%       & 97.756\%  \\
\hline
\end{tabular}
\caption{Non-Expert knowledge base concurrent validity against time}
\label{tab:neccurrent_time}
\end{table}

The second test of concurrent validity was performed using task membership. Again it is seen that the knowledge base of the expert out performs that of the non-expert. Neither knowledge base can predict task membership as well as the machine learning classifiers (table ~\cite{tab:ecurrenttask} and ~\cite{tab:necurrenttask}). %why?

\begin{table}[!htbp]
\centering
\begin{tabular}{|c|c|c|}
\hline
                                 & expertGrounded  & expertPref \\ \hline
Correctly Classified Instances   & 8.8319\%      & 9.4017\% \\
Incorrectly Classified Instances & 91.1681\%     & 90.5983\% \\
Kappa statistic                  & 0.034         & 0.0401    \\
Mean absolute error              & 0.0856        & 0.0856    \\
Root mean squared error          & 0.2069        & 0.2069    \\
Relative absolute error          & 98.9565\%     & 98.9251\% \\
Root relative squared error      & 99.478\%      & 99.4743\% \\
\hline
\end{tabular}
\caption{Expert knowledge base concurrent validity against task membership}
\label{tab:ecurrenttask}
\end{table}

\begin{table}[!htbp]
\centering
\begin{tabular}{|c|c|c|}
\hline
                                 & non-expertGrounded  & non-expertPref \\ \hline
Correctly Classified Instances   & 7.4074\%         & 7.4074\%  \\
Incorrectly Classified Instances & 92.5926\%        & 92.5926\%  \\
Kappa statistic                  & 0.0206           & 0.0206  \\
Mean absolute error              & 0.086            & 0.086   \\
Root mean squared error          & 0.2075           & 0.2075  \\
Relative absolute error          & 99.4773\%       & 99.4773\%  \\
Root relative squared error      & 99.7922\%       & 99.7922\%  \\
\hline
\end{tabular}
\caption{Non-Expert knowledge base concurrent validity against task membership}
\label{tab:necurrenttask}
\end{table}

\subsection{Convergent Validity}

In order to determine how well the constructs actually modeled MWL the convergent validity of these measures was determined. The convergent validity was determined by computing the correlation of each measure with existing measures of MWL. 

It can be seen that the expert's knowledge base correlates strongly with the other measures for MWL (table ~\ref{tab:corrmwlone}). There is a moderate correlation between other measures of MWL and and the non-expert's knowledge base. 

\begin{table}[!htbp]
\centering
\begin{tabular}{|c|c|c|c|}
\hline
                & NASA      &  WP        \\ \hline
time             & 0.2174278 & 0.2036869  \\
NASA             & 1.0000000 & 0.5836784 \\
WP               & 0.5836784 & 1.0000000 \\
expertGroundedExt  & 0.7233711 & 0.8593995 \\
expertPref1        & 0.7247067 & 0.8499664 \\
non-expertGroundedExt & 0.5518035 & 0.5648483 \\
non-expertPref1       & 0.5518035 & 0.5648483 \\
\hline
\end{tabular}
\caption{Pearson correlation of measures of MWL (1)}
\label{tab:corrmwlone}
\end{table}

Time does not correlate well with existing measures of MWL. This underlines one of the shortcomings of the machine learning approach for modeling constructs. A value must already exist in the data set that has a strong convergent validity with the construct being modeled. It was possible to predict task time most accurately using linear regression, however, this prediction is not useful to an expert if it doesn't have a high convergent validity with MWL. The only way to predict the value for a construct using machine learning is to have an expert label the data by hand. Labeling this data is a time consuming process as it will have to be done for very large data sets in order for the model to be trained accurately. As this work is tedious it may be difficult to guarantee that the expert has devoted equal attention to labeling all instances accurately. Moreover, the time that the expert spends labeling the data is taken away from their real work which may make many experts hesitant to get involved with such projects.

One situation in which this approach might be advantageous is to use the defeasible reasoning system to `label' the data instead of an expert having to endure the labour of labeling the data by hand. The implementation can be used to elicit a knowledge base from the expert and then run on training data applying labels to each row. Machine learning can then be used to determine the values for a construct in future instances of the data. This hybrid approach offers the best of both worlds as the expert can still obtain feedback about his knowledge base while the implementation can benefit from the speed and automatic computation of machine learning. Tables ~\ref{tab:mlhybrid1} and ~\ref{tab:mlhybrid2} show that ML can predict values for MWL well when provided with a labeled training set of data.

\begin{table}[!htbp]
\centering
\begin{tabular}{|c|c|c|c|}
\hline
                            & Simple Linear Regression   & decisionTable  & kstar\\ \hline
Correlation coefficient     & 0.6508        & 0.5861         & 0.2428       \\
Mean absolute error         & 9.991        & 10.7846        & 93.6672       \\
Root mean squared error     & 12.4932      & 13.6643       & 130.8713       \\
Relative absolute error     & 73.8692\%    & 79.7374\%        & 111.5627\%  \\
Root relative squared error & 75.8265\%     & 82.9345\%      & 111.5565\%   \\
\hline
\end{tabular}
\caption{Error and correlation results for prediciting MWL values according to expert's prefered extension (1)}
\label{tab:mlhybrid1}
\end{table}


\begin{table}[!htbp]
\centering
\begin{tabular}{|c|c|c|}
\hline
                            & additiveregression & Linear Regression\\ \hline
Correlation coefficient     & 0.8447    & 0.9392 \\
Mean absolute error         & 7.446      & 3.8686 \\
Root mean squared error     & 9.5961    & 5.6552  \\
Relative absolute error     & 55.0526\% & 28.6028\%\\
Root relative squared error & 58.2429\%  & 34.3239\%\\
\hline
\end{tabular}
\caption{Error and correlation results for predicting MWL values according to expert's prefered extension (2)}
\label{tab:mlhybrid2}
\end{table}

\section{Summary and Final Recommendations}

This chapter presented the results obtained in the experiment. Overall it is seen that linear regression performed best when presented with a prediction problem, however, it is limited to predicting features already present in the training data. This is a strong limitation of machine learning generally. In the case of MWL the value for time was chosen to represent the construct, however this was shown to have poor convergent validity with other measures of mental workload. The values for MWL developed from the experts knowledge base were found to have a strong convergent validity with another measure for MWL, NASA-TLX. It was noted that the DR implementation performed slowly and measures that could be taken in future implementations were described. Finally it was noted that the DR system could be used to label a training set used in machine learning in a hybrid approach. 