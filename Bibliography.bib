// -----------------------------------------------------------------------------
//
//	CHAPTER 1 INTRODUCTION
//
// -----------------------------------------------------------------------------

@book{turban2005decision,
	title={Decision Support Systems and Intelligent Systems},
	author={Turban, E. and Aronson, J.E. and Liang, T.P.},
	isbn={9780131230132},
	lccn={2004000997},
	url={https://books.google.ie/books?id=m0R5QgAACAAJ},
	year={2005},
	publisher={Prentice-Hall International}
}

@inproceedings{longo2012argumentation,
	title={Argumentation theory in health care},
	author={Longo, Luca and Kane, Bridget and Hederman, Lucy},
	booktitle={Computer-Based Medical Systems (CBMS), 2012 25th International Symposium on},
	pages={1--6},
	year={2012},
	organization={IEEE}
}

@article{murthy1998automatic,
	title={Automatic construction of decision trees from data: A multi-disciplinary survey},
	author={Murthy, Sreerama K},
	journal={Data mining and knowledge discovery},
	volume={2},
	number={4},
	pages={345--389},
	year={1998},
	publisher={Kluwer Academic Publishers}
}

@misc{kotsiantis2007supervised,
	title={Supervised machine learning: A review of classification techniques},
	author={Kotsiantis, Sotiris B and Zaharakis, I and Pintelas, P},
	year={2007}
}

@article{pollock1987defeasible,
  title={Defeasible reasoning},
  author={Pollock, John L},
  journal={Cognitive science},
  volume={11},
  number={4},
  pages={481--518},
  year={1987},
  publisher={Wiley Online Library}
}

@article{dung1995acceptability,
  title={On the acceptability of arguments and its fundamental role in nonmonotonic reasoning, logic programming and n-person games},
  author={Dung, Phan Minh},
  journal={Artificial intelligence},
  volume={77},
  number={2},
  pages={321--357},
  year={1995},
  publisher={Elsevier}
}

@inproceedings{vreeswijk2006algorithm,
  title={An algorithm to compute minimally grounded and admissible defence sets in argument systems},
  author={Vreeswijk, Gerard AW},
  booktitle={COMMA},
  pages={109--120},
  year={2006}
}

@article{zadeh1965fuzzy,
  title={Fuzzy sets},
  author={Zadeh, Lotfi A},
  journal={Information and control},
  volume={8},
  number={3},
  pages={338--353},
  year={1965},
  publisher={Elsevier}
}

@article{2011-d3,
  title = {D3: Data-Driven Documents},
  author = {Michael Bostock AND Vadim Ogievetsky AND Jeffrey Heer},
  journal = {IEEE Trans. Visualization \& Comp. Graphics (Proc. InfoVis)},
  year = {2011},
  url = {http://vis.stanford.edu/papers/d3}
}

@article{karacapilidis2001computer,
  title={Computer supported argumentation and collaborative decision making: the HERMES system},
  author={Karacapilidis, Nikos and Papadias, Dimitris},
  journal={Information systems},
  volume={26},
  number={4},
  pages={259--277},
  year={2001},
  publisher={Elsevier}
}

@article{twardy2004argument,
  title={Argument maps improve critical thinking},
  author={Twardy, Charles},
  journal={Teaching Philosophy},
  volume={27},
  number={2},
  pages={95--116},
  year={2004}
}

@inproceedings{matt2010combining,
  title={Combining statistics and arguments to compute trust},
  author={Matt, Paul-Amaury and Morge, Maxime and Toni, Francesca},
  booktitle={Proceedings of the 9th International Conference on Autonomous Agents and Multiagent Systems: volume 1-Volume 1},
  pages={209--216},
  year={2010},
  organization={International Foundation for Autonomous Agents and Multiagent Systems}
}

@book{witten2005data,
  title={Data Mining: Practical machine learning tools and techniques},
  author={Witten, Ian H and Frank, Eibe},
  year={2005},
  publisher={Morgan Kaufmann}
}

@book{mitchell2006discipline,
  title={The discipline of machine learning},
  author={Mitchell, Tom Michael},
  year={2006},
  publisher={Carnegie Mellon University, School of Computer Science, Machine Learning Department}
}

@article{alpaydinintroduction,
  title={Introduction to machine learning. 2004},
  author={Alpaydin, Ethem},
  journal={Cover, Copyright Page, Table of Contents for},
  pages={1--327}
}

@book{mohri2012foundations,
  title={Foundations of machine learning},
  author={Mohri, Mehryar and Rostamizadeh, Afshin and Talwalkar, Ameet},
  year={2012},
  publisher={MIT press}
}

@article{ng2000cs229,
  title={CS229 Lecture notes},
  author={Ng, Andrew}
}

@incollection{kohavi1995power,
  title={The power of decision tables},
  author={Kohavi, Ron},
  booktitle={Machine Learning: ECML-95},
  pages={174--189},
  year={1995},
  publisher={Springer}
}

@book{jensen1996introduction,
  title={An introduction to Bayesian networks},
  author={Jensen, Finn V},
  volume={210},
  year={1996},
  publisher={UCL press London}
}

@article{arel2010deep,
  title={Deep machine learning-a new frontier in artificial intelligence research [research frontier]},
  author={Arel, Itamar and Rose, Derek C and Karnowski, Thomas P},
  journal={Computational Intelligence Magazine, IEEE},
  volume={5},
  number={4},
  pages={13--18},
  year={2010},
  publisher={IEEE}
}

@article{reiter1980logic,
  title={A logic for default reasoning},
  author={Reiter, Raymond},
  journal={Artificial intelligence},
  volume={13},
  number={1},
  pages={81--132},
  year={1980},
  publisher={Elsevier}
}

@article{pollock1987defeasible,
  title={Defeasible reasoning},
  author={Pollock, John L},
  journal={Cognitive science},
  volume={11},
  number={4},
  pages={481--518},
  year={1987},
  publisher={Wiley Online Library}
}

@article{modgil2014aspic+,
  title={The ASPIC+ framework for structured argumentation: a tutorial},
  author={Modgil, Sanjay and Prakken, Henry},
  journal={Argument \& Computation},
  volume={5},
  number={1},
  pages={31--62},
  year={2014},
  publisher={Taylor \& Francis}
}

@TechReport {export:69588,
abstract     = {<p>A Bayesian network is a graphical model that encodes probabilistic
                relationships among variables of interest. When used in conjunction with
                statistical techniques, the graphical model has several advantages for data
                analysis. One, because the model encodes dependencies among all variables, it
                readily handles situations where some data entries are missing. Two, a Bayesian
                network can be used to learn causal relationships, and hence can be used to gain
                understanding about a problem domain and to predict the consequences of
                intervention. Three, because the model has both a causal and probabilistic
                semantics, it is an ideal representation for combining prior knowledge (which
                often comes in causal form) and data. Four, Bayesian statistical methods in
                conjunction with bayesian networks offer an efficient and principled approach for
                avoiding the overfitting of data. In this paper, we discuss methods for
                constructing Bayesian networks from prior knowledge and summarize Bayesian
                statistical methods for using data to improve these models. With regard to the
                latter task, we describe methods for learning both the parameters and structure
                of a Bayesian network, including techniques for learning with incomplete data. In
                addition, we relate Bayesian-network methods for learning to techniques for
                supervised and unsupervised learning. We illustrate the graphical-modeling
                approach using a real-world case study.</p>},
author       = {David Heckerman},
institution  = {Microsoft Research},
month        = {March},
number       = {MSR-TR-95-06},
pages        = {57},
title        = {A Tutorial on Learning With Bayesian Networks},
url          = {http://research.microsoft.com/apps/pubs/default.aspx?id=69588},
year         = {1995},
}


@inproceedings{cleary1995k,
  title={K*: An instance-based learner using an entropic distance measure},
  author={Cleary, John G and Trigg, Leonard E and others},
  booktitle={Proceedings of the 12th International Conference on Machine learning},
  volume={5},
  pages={108--114},
  year={1995}
}


@inproceedings{pelleg2000x,
  title={X-means: Extending K-means with Efficient Estimation of the Number of Clusters.},
  author={Pelleg, Dan and Moore, Andrew W and others},
  booktitle={ICML},
  pages={727--734},
  year={2000}
}

@article{kohavi1997improving,
  title={Improving simple bayes},
  author={Kohavi, Ron and Becker, Barry and Sommerfield, Dan},
  year={1997},
  publisher={Citeseer}
}

@article{grunwald2005tutorial,
  title={A tutorial introduction to the minimum description length principle},
  author={Gr{\"u}nwald, Peter},
  year={2005}
}

@phdthesis{longo2014formalising,
  title={Formalising Human Mental Workload as a Defeasible Computational Concept},
  author={Longo, Luca},
  year={2014},
  school={Trinity College}
}

@book{price2013research,
  title={Research Methods in Psychology: Core Concepts and Skills},
  author={Price, P. and Jhangiani, R.},
  series={BC open textbook collection},
  url={http://books.google.ie/books?id=7tIWngEACAAJ},
  year={2013}
}

@book{meshkati2011human,
  title={Human mental workload},
  author={Meshkati, N and Hancock, PA},
  year={2011},
  publisher={Elsevier}
}